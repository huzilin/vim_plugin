# Spark-SQL with Python

## pyspark内sc包含
```python
sc.__dict__ 
{'_accumulatorServer': <pyspark.accumulators.AccumulatorServer instance at 0x2b33248>, '_conf': <pyspark.conf.SparkConf object at 0x2b2fb50>, '_javaAccumulator': JavaObject id=o17, '_jsc': JavaObject id=o12, 'pythonExec': 'python', '_callsite': CallSite(function='getOrCreate', file='/root/spark-2.0.0-bin-hadoop2.7//python/pyspark/shell.py', linenum=43), 'pythonVer': '2.6', 'appName': u'PySparkShell', 'environment': {}, '_unbatched_serializer': PickleSerializer(), '_pickled_broadcast_vars': set([]), 'master': u'local[*]', '_python_includes': [], '_temp_dir': u'/tmp/spark-54012421-3053-4676-af07-77415d77e279/pyspark-3e0a428b-2e8e-43bf-ad07-e4a12c979875', 'sparkHome': None, '_batchSize': 0, 'profiler_collector': None, 'serializer': AutoBatchedSerializer(PickleSerializer())}
```

## python 使用Spark连接MySQL的示例
```python
from pyspark.sql.context import SQLContext
from pyspark.context import SparkContext
sc = SparkContext(appName="mysqltest")
sqlContext = SQLContext(sc)
df = sqlContext.read.format("jdbc").options(url="jdbc:mysql://127.0.0.1:3306/test?user=root&password=123",dbtable="t1").load()
df.show()
```

## 具体使用方法
### 把DataFarm转化成一张虚拟表
```python
df.registerTempTable("t1")
```

### 对虚拟表执行sql语句
```python
>>> a=sqlContext.sql("select id from t1 where id=1").show()
+---+
| id|
+---+
|  1|
+---+
>>> a=sqlContext.sql("select id from t1 where id=1")
>>> DataFrame[id: int]
>>> a.show()
    +---+
    | id|
    +---+
    |  1|
    +---+
```

### cross join
```python
from pyspark.sql.context import SQLContext
from pyspark.context import SparkContext
from pyspark.conf import SparkConf
_conf=SparkConf()
_conf.set("spark.sql.crossJoin.enabled","true")
sc = SparkContext(appName="mysqltest",conf=_conf)
sqlContext = SQLContext(sc)
t1 = sqlContext.read.format("jdbc").options(url="jdbc:mysql://127.0.0.1:3306/test?user=root&password=123",dbtable="t1").load()
t2 = sqlContext.read.format("jdbc").options(url="jdbc:mysql://127.0.0.1:3306/test?user=root&password=123",dbtable="t2").load()
t1.registerTempTable("t1")
t2.registerTempTable("t2")
ret=sqlContext.sql("select t1.id,t1.c2,t2.c1,t2.c2 from t1,t2, (select id from t1 where id>1) t3 where t1.id=t3.id and t1.id=t2.c1")
ret.show()
```

### 取表的部分数据
```python
t1.select(t1.id).where(t1.id>1).collect()
```
## 语句支持情况
TPCH测试中，不包含函数(非聚合函数)的语句都支持。
