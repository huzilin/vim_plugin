['Spark-SQL', 'with', 'Python', 'pyspark', 'python', '__dict__', '_accumulatorServer', '<pyspark', 'accumulators', 'AccumulatorServer', 'instance', 'x2b33248', '_conf', 'conf', 'SparkConf', 'object', 'x2b2fb50', '_javaAccumulator', 'JavaObject', '_jsc', 'pythonExec', '_callsite', 'CallSite', 'function', 'getOrCreate', 'file', 'root', 'spark-2', 'bin-hadoop2', 'shell', 'linenum', 'pythonVer', 'appName', 'PySparkShell', 'environment', '_unbatched_serializer', 'PickleSerializer', '_pickled_broadcast_vars', 'master', 'local', '_python_includes', '_temp_dir', 'spark-54012421-3053-4676-af07-77415d77e279', 'pyspark-3e0a428b-2e8e-43bf-ad07-e4a12c979875', 'sparkHome', 'None', '_batchSize', 'profiler_collector', 'serializer', 'AutoBatchedSerializer', 'Spark', 'MySQL', 'from', 'context', 'import', 'SQLContext', 'SparkContext', 'appName="mysqltest"', 'sqlContext', 'read', 'format', 'jdbc', 'options', 'url="jdbc:mysql://127.0.0.1:3306/test?user=root&password=123"', 'dbtable="t1"', 'load', 'show', 'DataFarm', 'registerTempTable', 'select', 'where', 'DataFrame', 'cross', 'join', 'spark', 'crossJoin', 'enabled', 'true', 'dbtable="t2"', 'collect']
